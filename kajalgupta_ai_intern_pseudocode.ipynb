{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Object and Sub-Object Detection\n",
        "###Approach:\n",
        "Object Detection: We can utilize an object detection model such as YOLO (You Only Look Once) or SSD (Single Shot Multibox Detector), which are popular for real-time object detection. These models can be fine-tuned or trained to detect various objects (e.g., \"Person,\" \"Car\").\n",
        "\n",
        "Sub-Object Detection: For detecting sub-objects like \"Helmet\" or \"Tire,\" we will need to either:\n",
        "\n",
        "Use a multi-class detector that includes both objects and sub-objects in the same model, or\n",
        "Use a two-stage pipeline where the primary object is first detected, and a secondary sub-object detection model focuses on detecting sub-objects within the bounding box of the primary object.\n",
        "Hierarchical Association:\n",
        "After detecting an object and sub-object, a hierarchical structure will be created where each detected object has a unique ID. Each sub-object will be linked to its corresponding parent object.\n",
        "\n",
        "The hierarchical structure will be maintained as follows:\n",
        "\n",
        "Main Object ID (e.g., Person, Car) will be assigned a unique identifier.\n",
        "Sub-objects will be linked to the main object using that identifier, ensuring the system can establish relationships between them."
      ],
      "metadata": {
        "id": "5WCBJ9BsCIhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoNTcSK8B-81"
      },
      "outputs": [],
      "source": [
        "detected_objects = []\n",
        "\n",
        "# main object detection\n",
        "for obj in detected_objects:\n",
        "    obj_id = unique_object_id()\n",
        "    main_object = {\n",
        "        \"object\": obj.name,\n",
        "        \"id\": obj_id,\n",
        "        \"bbox\": obj.bounding_box\n",
        "    }\n",
        "\n",
        "    # Sub-object detection within the bounding box\n",
        "    for sub in obj.detected_sub_objects:\n",
        "        sub_object = {\n",
        "            \"object\": sub.name,\n",
        "            \"id\": unique_sub_object_id(),\n",
        "            \"bbox\": sub.bounding_box\n",
        "        }\n",
        "        main_object[\"subobject\"] = sub_object  # Link sub-object to main object\n",
        "\n",
        "    # Store the result\n",
        "    results.append(main_object)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#JSON Output Format\n",
        "The output should adhere to the hierarchical JSON format as described, capturing both the object and its sub-objects:\n",
        "\n",
        "{\n",
        "  \"object\": \"Person\",\n",
        "  \"id\": 1,\n",
        "  \"bbox\": [100, 200, 300, 400],\n",
        "  \"subobject\": {\n",
        "    \"object\": \"Helmet\",\n",
        "    \"id\": 1,\n",
        "    \"bbox\": [120, 220, 180, 280]\n",
        "  }\n",
        "}\n",
        "object: The name of the detected object (e.g., \"Person\").\n",
        "id: Unique identifier for the object.\n",
        "bbox: Bounding box of the object, represented as [x1, y1, x2, y2].\n",
        "subobject: Contains information about the associated sub-object, including its name, ID, and bounding box."
      ],
      "metadata": {
        "id": "RYxq_XCPCaRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sub-Object Image Retrieval\n",
        "To retrieve and save cropped images of specific sub-objects, we need to implement a function that uses the bounding box of the detected sub-object and crops the image from the original frame.\n",
        "\n",
        "##Implementation Steps:\n",
        "1.Use the bounding box from the detection to crop the sub-object region.\n",
        "2.Save the cropped image of the sub-object for later retrieval."
      ],
      "metadata": {
        "id": "USnbsdnACzq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def crop_subobject(image, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cropped_image = image[y1:y2, x1:x2]\n",
        "    return cropped_image\n",
        "\n",
        "def save_subobject_image(cropped_image, sub_object_id):\n",
        "    file_path = f\"subobject_{sub_object_id}.png\"\n",
        "    cv2.imwrite(file_path, cropped_image)\n"
      ],
      "metadata": {
        "id": "oZH1rI7xCyLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference Speed Optimization\n",
        "To meet the real-time processing requirement of 10-30 FPS on CPU:\n",
        "\n",
        "1.Model Optimization: Use optimized models such as MobileNetV2 or Tiny YOLO to reduce computational load.\n",
        "2.Batch Processing: Process multiple frames in batches where possible.\n",
        "3.Framework Optimization: Use ONNX (Open Neural Network Exchange) or TensorRT for optimized inference on the CPU.\n",
        "4.Multithreading/Concurrency: Split the video stream processing into multiple threads to utilize CPU resources more efficiently."
      ],
      "metadata": {
        "id": "44zp6DV0DQWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture('sample_video.mp4')\n",
        "fps = 0\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    detect_objects(frame)\n",
        "\n",
        "    end_time = time.time()\n",
        "    fps = 1 / (end_time - start_time)\n",
        "    print(f\"FPS: {fps}\")\n",
        "    if fps >= 10 and fps <= 30:\n",
        "        break\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "1fchGdSZDFYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modularity and Extensibility\n",
        "To ensure that the system is modular:\n",
        "\n",
        "1.Object Detection Module: Create separate classes or functions for detecting different objects.\n",
        "2.Sub-Object Detection Module: Implement independent sub-object detectors that can be swapped or extended easily.\n",
        "3.Configuration Files: Use configuration files (e.g., JSON, YAML) to specify which object-sub-object pairs should be detected, making it easier to add new detections."
      ],
      "metadata": {
        "id": "sFSomm4_DehJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#yolov5 implmentation"
      ],
      "metadata": {
        "id": "ChE9sTc5D5Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python torch torchvision pyyaml\n",
        "pip install yolov5  # For YOLOv5 model\n"
      ],
      "metadata": {
        "id": "e0Jo4SbbDYm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the library\n",
        "import cv2\n",
        "import torch\n",
        "import json\n",
        "import uuid\n",
        "import time"
      ],
      "metadata": {
        "id": "1KCAKrV2EFPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load pre-trained YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
      ],
      "metadata": {
        "id": "Og-K1zhuENLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to detect objects and sub-objects\n",
        "def detect_objects(frame):\n",
        "    results = model(frame)  # Perform inference on the frame\n",
        "    return results"
      ],
      "metadata": {
        "id": "vL0lkvMZEQ7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a unique ID generator function\n",
        "def generate_unique_id():\n",
        "    return str(uuid.uuid4())"
      ],
      "metadata": {
        "id": "Q31ePpLpESuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the detection results into the required JSON format\n",
        "def generate_json_output(detected_objects):\n",
        "    results_json = []\n",
        "    for obj in detected_objects:\n",
        "        main_object = {\n",
        "            \"object\": obj['name'],\n",
        "            \"id\": generate_unique_id(),\n",
        "            \"bbox\": obj['bbox'] }"
      ],
      "metadata": {
        "id": "caA3CwLVEVwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        # Assuming sub-object is a part of the object (e.g., helmet for person)\n",
        "        if 'subobject' in obj:\n",
        "            sub_object = {\n",
        "                \"object\": obj['subobject']['name'],\n",
        "                \"id\": generate_unique_id(),\n",
        "                \"bbox\": obj['subobject']['bbox']\n",
        "            }\n",
        "            main_object[\"subobject\"] = sub_object\n",
        "\n",
        "        results_json.append(main_object)\n",
        "    return json.dumps(results_json, indent=4)"
      ],
      "metadata": {
        "id": "vhyqEoo2EYll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process video frames and detect objects\n",
        "def process_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = 0\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        start_time = time.time()\n",
        "        results = detect_objects(frame)\n",
        "        detected_objects = []\n",
        "\n",
        "        # Parsing results into detected objects with sub-objects\n",
        "        for *xyxy, conf, cls in results.xywh[0]:\n",
        "            name = model.names[int(cls)]\n",
        "            bbox = [int(x) for x in xyxy]\n",
        "            detected_objects.append({\n",
        "                'name': name,\n",
        "                'bbox': bbox\n",
        "            })"
      ],
      "metadata": {
        "id": "qpSYVQKtEega"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating hierarchical JSON output\n",
        "json_output = generate_json_output(detected_objects)\n",
        "print(json_output)"
      ],
      "metadata": {
        "id": "3nyl3dKGEi2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating FPS\n",
        "end_time = time.time()\n",
        "fps = 1 / (end_time - start_time)\n",
        "frame_count += 1\n",
        "if frame_count % 10 == 0:\n",
        "  print(f\"FPS: {fps:.2f}\")\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "7LYn3OgJEjKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the video processing function with a sample video\n",
        "process_video('sample_video.mp4')\n"
      ],
      "metadata": {
        "id": "mz7Nt0MSD8a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sub-Object Image Retrieval\n",
        "This function will crop images of detected sub-objects (for example, helmets for people) and save them to disk."
      ],
      "metadata": {
        "id": "cMkR1sucFVJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_subobject_image(frame, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cropped_image = frame[y1:y2, x1:x2]\n",
        "    return cropped_image\n",
        "\n",
        "def save_subobject_image(cropped_image, sub_object_id):\n",
        "    filename = f\"subobject_{sub_object_id}.png\"\n",
        "    cv2.imwrite(filename, cropped_image)\n",
        "    print(f\"Saved image as {filename}\")\n",
        "\n",
        "# Sample function to demonstrate cropping and saving sub-object images\n",
        "def process_and_save_subobject_images(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detect objects and sub-objects in the frame\n",
        "        results = detect_objects(frame)\n",
        "        for *xyxy, conf, cls in results.xywh[0]:\n",
        "            name = model.names[int(cls)]\n",
        "            bbox = [int(x) for x in xyxy]\n",
        "\n",
        "            # Save the sub-object image (assuming sub-object detection)\n",
        "            sub_object_id = generate_unique_id()\n",
        "            cropped_image = crop_subobject_image(frame, bbox)\n",
        "            save_subobject_image(cropped_image, sub_object_id)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Run the function to save sub-object images\n",
        "process_and_save_subobject_images('sample_video.mp4')\n"
      ],
      "metadata": {
        "id": "LPFSjO0mFBbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}